import math
import operator
from random import uniform
import numpy as np
from collections import defaultdict
import numpy as np
import operator as op
#from differential_evolution_functions import Mutation,Repair_Solution,Select_Random
from cluster_validity_indices.anti_redundancy import Sent_to_sent
#from cluster_validity_indices.sent_to_caption import Sent_to_caption

import random
data=np.array
matrix=np.array



class MBDE():
    def __init__(self, Mating_Pool, population, current_solution_index, current_solution, SS_WMD_Matrix, MAX_TFIDF_matrix, MAX_TWEET_length_matrix, max_len_solution,  b=6, CR=0.8, F=0.8, min_sent_in_summary=10, max_sent_in_summary=30 ):
        """
        :param Mating_Pool: Generated mating pool for current solution
        :param population: Population containing solutions
        :param current_solution_index: Current solution index in population
        :param current_solution: Current solution vector
        :param b: MBDE Control parameter
        :param CR: #MBDE Control parameter-Crossover Probability
        :param F: #MBDE Control parameter
        :param SS_WMD_Matrix: Sentence to Sentence WMD matrix
        :param MAX_TFIDF_matrix: TF-IDF value of each tweet
        :param min_tweet_in_summary: Minimum number of tweets that can be in summary
        :param max_tweet_in_summary: Maximum number of tweets that can be in summary
        """
        self.population=population
        self.current_solution=current_solution
        self.current_solution_index=current_solution_index
        self.Q=Mating_Pool
        self.F=F
        self.b=b
        self.r=3
        self.CR=CR
        self.SS_WMD_Matrix=SS_WMD_Matrix
        self.MAX_TFIDF_matrix=MAX_TFIDF_matrix
        self.MAX_TWEET_Length_matrix=MAX_TWEET_length_matrix
        self.Minimum_sent_in_summary=min_sent_in_summary
        self.Maximum_sent_in_summary=max_sent_in_summary
        self.max_length_solution=max_len_solution

    def ncr(self):
        """
        :param n: length of mating pool
        :param r: number of solution we need to take to make combinations
        :return: no. of possible combinations
        """
        n1=len(self.Q)
        r1 = min(self.r, n1 - self.r)
        if r1 == 0: return 1
        numer = reduce(op.mul, xrange(n1, n1 - r1, -1))
        denom = reduce(op.mul, xrange(1, r1 + 1))
        return numer // denom


    """This function return the combinations"""
    def prob(self, parent1, parent2, parent3):
        """
        :param parent1: First random solution from mating pool
        :param parent2: second random solution from mating pool
        :param parent3: third random solution from mating pool
        :return: probability of each component
        """

        p_list = []
        i = 0
        n2 = len(parent1)
        while (i < n2):
            x1 = parent1[i]
            x2 = parent2[i]
            x3 = parent3[i]
            p = float(1) / (1 + math.exp((((2 * self.b * (x1 + (self.F * (x2 - x3) - .5))) / (1 + (2 *self.F))) * (-1))))
            p_list.append(p)
            i += 1
        # print 'Probability list in function: \n\n',p_list      # probability list is generated
        return p_list


    def mutation(self, prob_list):
        """
        :param prob_list: probability list generated by prob(parent1, parent2, parent3, b=6, F=0.8) function
        :return: mutant vector
        """
        i = 0
        p_list = prob_list
        mutant = np.random.randint(0, 1, (len(p_list)))

        while (i < len(p_list)):
            rand = random.uniform(0, 1)
        # print 'random no = ',rand
            if rand <= p_list[i]:
                 mutant[i] = 1
            else:
                mutant[i] = 0
            i += 1
        # print 'generated Mutant : \n\n',mutant      #Mutant is generated
        return mutant



    """THis function generates a new solution using crossover"""
    def crossover(self,  mutant):
        """
        :param mutant: Mutant for generated in the mutation function
        :return: generates a mutated new solution
        """
        j = 0
        #CR = .2
        crossover = np.random.randint(0, 1, (len(mutant)))
        while (j < len(mutant)):
            aa=self.current_solution
            tar_bit = aa[j] #self.population[self.current_solution_index, j]
            mut_bit = mutant[j]
            # print 'target bit : ',tar_bit
            # print 'mutant bit : ',mut_bit
            randj = random.uniform(0, 1)
            randi = random.randint(0, len(mutant))
            # print 'randj :',randj
            # print 'randi :',randi
            if randj <= self.CR or j == randi:
                crossover[j] = mut_bit
            else:
                crossover[j] = tar_bit
            j += 1

        # print 'generated Trial : ',crossover      #Trial is generated
        return crossover

    def one_count(self, trial):
        """
        :param trial:  trial vector generated using croosover function
        :return: count the number of ones in trial vector
        """
        #print "type of trial solution : ", type(trial), type(trial.tolist())

        ones_count=trial.tolist().count(1)
        return ones_count

    def Generate(self):
        """
        :param Q: Mating pool
        :param population: Archive population
        :param i: current solution index
        :param x: current solution
        :param max_solution_length: maximum length of the solutions
        :param b: constant
        :param CR: cross-over probability
        :return: New solution
        """
        total_combination=self.ncr()
        count_comination=1
        # Unique=[]
        #mp=uniform(0,1)
        trial_list = []
        word_len = []
        while count_comination<=total_combination:
            my_randoms = random.sample(xrange(0, len(self.Q)), 3)
            #print( "random solution no. choosen for {0}th solution (combination {1}) :".format(self.current_solution_index, count_comination), my_randoms)
            all_solution_vector=[]
            for ww in self.population:
                #print "ind :", ww
                all_solution_vector.append(ww.features)

            p1=all_solution_vector[self.Q[my_randoms[0]]]
            p2=all_solution_vector[self.Q[my_randoms[1]]]
            p3=all_solution_vector[self.Q[my_randoms[2]]]

            probability=self.prob(p1,p2,p3)          #probability vector
            mutant_vector=self.mutation(probability)    #binary vector
            trial_sol = self.crossover(mutant_vector)  # Trial Generated
            ones_count=self.one_count(trial_sol)     #number of ones in generated trial solution
            #print "ones count  :", ones_count
            word_len.append(ones_count)
            trial_list.append(trial_sol)

            count_comination+=1

        solutions_within_range=[]     #solution is within minimum and maximum number of sentences to be in the summary
        no_of_ones_in_solution_within_ranges=[]
        for j in range(len(word_len)):
            if word_len[j]<=self.Maximum_sent_in_summary and word_len[j]>=self.Minimum_sent_in_summary:
                  solutions_within_range.append(trial_list[j])
                  no_of_ones_in_solution_within_ranges.append(word_len[j])
        if len(solutions_within_range) <> 0 and random.uniform(0,1) < 0.8:
            #print("new solution generated using SOM")
            tot_sol_leng = len(solutions_within_range)
            rand_no = random.randint(0,tot_sol_leng-1)
            return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]
            #except:
        elif random.uniform(0,1) < 0.8:
           #print("New solution generated using sorted average tweet length objective value of a solution")
           for kk in range(len(word_len)) :
               if random.uniform(0,1) < 0.5:
                    solution=trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives=[] #store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj]==1:
                            sentence_objectives.append(self.MAX_TWEET_Length_matrix[jj])
                        else:
                            sentence_objectives.append(-100+self.MAX_TWEET_Length_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)), key=lambda k: sentence_objectives[k], reverse=True) #sort the tweets in reverse order and return the indices
                    #print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter=0
                    while(x<>0):
                        new_solution[sorted_objective_list[counter]]=1
                        counter+=1
                        x-=1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())
               else:
                   solution = trial_list[kk]
                   new_solution = np.zeros(self.max_length_solution)
                   sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                   for jj in range(len(solution)):
                       if solution[jj] == 1:
                           sentence_objectives.append(self.MAX_TFIDF_matrix[jj])
                       else:
                           sentence_objectives.append(-100 + self.MAX_TFIDF_matrix[jj])
                   sorted_objective_list = sorted(range(len(sentence_objectives)), key=lambda k: sentence_objectives[k],
                                                  reverse=True)  # sort the tweets in reverse order and return the indices
                   # print("sorted list :", sorted_objective_list)
                   x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                   no_of_ones_in_solution_within_ranges.append(x)
                   counter = 0
                   while (x <> 0):
                       new_solution[sorted_objective_list[counter]] = 1
                       counter += 1
                       x -= 1
                   # no_of_ones_in_solution_within_ranges.append(x)
                   solutions_within_range.append(new_solution.tolist())
           #tot_sol_leng = len(solutions_within_range)
           #rand_no = random.randint(0, tot_sol_leng)
           return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]

        else:

            if random.uniform(0, 1) < 0.5:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_TWEET_Length_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                           key=lambda k: sentence_objectives[k],
                                           reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x <> 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())
            else:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_TFIDF_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                           key=lambda k: sentence_objectives[k],
                                           reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x <> 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())


            #tot_sol_leng = len(solutions_within_range)
            #rand_no = random.randint(0, tot_sol_leng - 1)
            return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]








    # def Generate(self):
    #   """
    #     :param Q: Mating pool
    #     :param population: Archive population
    #     :param i: current solution index
    #     :param x: current solution
    #     :param max_solution_length: maximum length of the solutions
    #     :param b: constant
    #     :param CR: cross-over probability
    #     :return: New solution
    #   """
    #   total_combination=self.ncr()
    #   count_comination=1
    #   Unique=[]
    #   #mp=uniform(0,1)
    #   trial_list = []
    #   word_len = []
    #   while count_comination< total_combination:
    #         my_randoms = random.sample(xrange(0, len(self.Q)), 3)
    #         #print( "random solution no. choosen for {0}th solution (combination {1}) :".format(self.current_solution_index, count_comination), my_randoms)
    #         all_solution_vector=[]
    #         for ww in self.population:
    #             #print "ind :", ww
    #             all_solution_vector.append(ww.features)
    #
    #
    #         p1=all_solution_vector[self.Q[my_randoms[0]]]
    #         p2=all_solution_vector[self.Q[my_randoms[1]]]
    #         p3=all_solution_vector[self.Q[my_randoms[2]]]
    #
    #         probability=self.prob(p1,p2,p3)          #probability vector
    #         mutant_vector=self.mutation(probability)    #binary vector
    #         trial_sol = self.crossover(mutant_vector)  # Trial Generated
    #         ones_count=self.one_count(trial_sol)     #number of ones in generated trial solution
    #         #print "ones count  :", ones_count
    #         word_len.append(ones_count)
    #         trial_list.append(trial_sol)
    #         count_comination+=1
    #
    #   #try:
    #   solutions_within_range=[]     #solution is within minimum and maximum number of sentences to be in the summary
    #   no_of_ones_in_solution_within_ranges=[]
    #   for j in range(len(word_len)):
    #         if word_len[j]<=self.Maximum_sent_in_summary and word_len[j]>=self.Minimum_sent_in_summary:
    #               solutions_within_range.append(trial_list[j])
    #               no_of_ones_in_solution_within_ranges.append(word_len[j])
    #   if len(solutions_within_range) <> 0:
    #         return solutions_within_range, no_of_ones_in_solution_within_ranges
    #   #except:
    #   else:
    #       print( "solution generated due to randomness")
    #       AA1=[]
    #       BB1=[]
    #       x = random.randint(self.Maximum_sent_in_summary, self.Minimum_sent_in_summary + 1)
    #       one = np.ones(x)
    #       zero = np.zeros(self.max_length_solution - x)
    #       sol_arr = np.concatenate((one, zero))
    #       np.random.shuffle(sol_arr)
    #       AA1.append(sol_arr.tolist())
    #       BB1.append(one)
    #       return AA1, BB1
    #       # """Choose the generated trial solutions having max. anti-redundancy or maximum similarity with caption.
    #       # Any objective functions can be used based on random probabiility"""
    #       # trial_objective_value=[]
    #       # rand_prob=uniform(0,1)
    #       # AA1=[]
    #       # BB1=[]
    #       # if rand_prob<0.5:  #anti-redundancy objective is choosen
    #       #   print "Trail solution choosen based on max. anti-redundancy function value"
    #       #   for s in range(len(word_len)):
    #       #       trial_objective_value.append(Sent_to_sent(self.SS_WMD_Matrix, trial_list[s]))
    #       #   sorted_objective_list= sorted(range(len(trial_objective_value)), key=lambda k: trial_objective_value[k], reverse=True)
    #       #   AA1.append(trial_list[sorted_objective_list[0]])
    #       #   BB1.append(word_len[sorted_objective_list[0]])
    #       #   return AA1, BB1
    #       # else:
    #       #     print "Trail solution choosen based on max. sent_to_caption function value"
    #       #     for s in range(len(word_len)):
    #       #         trial_objective_value.append(Sent_to_caption(self.SC_WMD_Matrix, trial_list[s],1))
    #       #     sorted_objective_list = sorted(range(len(trial_objective_value)), key=lambda k: trial_objective_value[k],reverse=True)
    #       #     AA1.append(trial_list[sorted_objective_list[0]])
    #       #     BB1.append(word_len[sorted_objective_list[0]])
    #       #     return AA1, BB1






class MatingPool_Generation():
    def __init__(self):
        pass


    def eu_dist(self, inp_winning_neuron_index, neuron_weights):
        '''
        This function takes two arguments i.e. index of a particular and the neuron set and returns a list of ED between that particular neuron and other neurons weight vectors
        '''
        """        
        :param inp_winning_neuron_index:  winning neuron index for a current solution
        :param neuron_weights: trained SOM neuron's weight vectors
        :return: returns a list of Euclidean Distance between that winning neurons' weight and other neurons's weights
        """

        i = 0
        distnace_list = []
        numner_of_neurons = len(neuron_weights)
        while (i < numner_of_neurons):
            dist1 = np.linalg.norm(neuron_weights[inp_winning_neuron_index] - neuron_weights[i])  # Calculating ED between Individual[i]
            distnace_list.append(dist1)
            i = i + 1
        return distnace_list
        # Fetching Minimum ED

    def mating_pool_generation(self, H, L, solution_no,  neuron_weight,  pop_length, beta=0.8):
        """
        :param H: Number of solutions in mating pool of each neuron (size of H<=no. of neuron in Lattice)
        :param L: mapping neuron indices correspond to solutions in population
        :param i: current solution no.
        :param x: current solution
        :param matrix: neuron weight matrix
        :param beta: threshold probability for generating mating pool
        :return: mating pool of current solution x
        """
        winning_neuron_index=L[solution_no] ##winning neuron index correspond to current solution
        distnace_list_winning_and_other_neurons=self.eu_dist(winning_neuron_index, neuron_weight)
        sorted_x = sorted(range(len(distnace_list_winning_and_other_neurons)), key=lambda k: distnace_list_winning_and_other_neurons[k])
        #sorted_x=sorted(distnace_list_winning_and_other_neurons)
        counter=0
        mating_pool=[]
        flag=0
        if uniform(0, 1) < beta: # and counter < H + 1:
            for k in sorted_x:
                if counter<H+1:
                    # H+1 is because it will add itself in mating pool list which we need to remove to make the mating pool size as H.
                    found_solution_index = L.index(k)
                    mating_pool.insert(counter, found_solution_index)
                    counter += 1

            if len(mating_pool) == H + 1 and solution_no in mating_pool:
                #print("Mating pool generating using SOM ")
                mating_pool.remove(solution_no)
                return np.asarray(mating_pool), flag

        else:
            # print "Random probability is greater than Beta for this neuron therefore assign population as the mating pool for neuron {0}".format(i)
            mating_pool = list(np.arange(0, pop_length))
            flag=1
            if solution_no in mating_pool:
                mating_pool.remove(solution_no)
            # print  "Mating pool for solution {} in population".format(i),mating_pool
            return np.asarray(mating_pool), flag









#
#
# def generate_matingPool(H, L, i, x,  matrix, pop_length, beta=0):   #H, i, A[i],A_K[i], neuron_weight, neuron_K, pop_length, beta=0.7
#     """
#     :param H: Number of solutions in mating pool of each neuron (size of H<=no. of neuron in Lattice)
#     :param L: mapping neuron indices correspond to solutions in population
#     :param i: current solution no.
#     :param x: current solution
#     :param matrix: neuron weight matrix
#     :param beta: threshold probability for generating mating pool
#     :return: mating pool of current solution x
#     """
#     dd={}
#     mating_pool=[]
#     for j in range(len(matrix)):
#              temp1=np.copy(x)
#              temp2 = np.copy(matrix[j])
#              dist = np.linalg.norm(temp1- temp2)  #np.linalg.norm(temp1 - temp2)
#              dd[j] = dist
#     sorted_x = sorted(dd.items(), key=operator.itemgetter(1))
#
#     counter=0
#
#     for k, v in sorted_x:
#             if  uniform(0, 1) < beta and counter<H+1: #H+1 is because it will add itself in mating pool list which we need to remove to make the mating pool size as H.
#                  found_index =L.index(k)
#                  mating_pool.insert(counter,found_index)
#                  counter+=1
#
#
#     if len(mating_pool)==H+1 and i in mating_pool:
#             mating_pool.remove(i)
#             return np.asarray(mating_pool)
#
#     else:
#         #print "Random probability is greater than Beta for this neuron therefore assign population as the mating pool for neuron {0}".format(i)
#         mating_pool=list(np.arange(0, pop_length))
#         if i in mating_pool:
#             mating_pool.remove(i)
#         #print  "Mating pool for solution {} in population".format(i),mating_pool
#         return np.asarray(mating_pool)



